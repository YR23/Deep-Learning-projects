{
  "cells": [
    {
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true
      },
      "cell_type": "code",
      "source": "import numpy as np\nimport pandas as pd \nfrom keras.utils import np_utils\nimport os\nimport keras\nimport gensim\nfrom gensim.models import Word2Vec\nfrom sklearn.decomposition import PCA\n%matplotlib inline\nimport matplotlib.pyplot as plt\nfrom numpy import array\nfrom keras.utils import to_categorical\nfrom numpy import argmax\nfrom keras import Sequential\nfrom keras.layers import LSTM,Input,Lambda,concatenate, Dense,Dropout,GRU,BatchNormalization\nfrom keras.utils import to_categorical\nfrom keras.preprocessing.text import one_hot\nfrom keras.preprocessing.sequence import pad_sequences\nfrom keras.preprocessing import text as keras_text, sequence as keras_seq\nimport re\nimport keras.backend as K\nfrom keras.models import Model\nfrom keras.optimizers import Adadelta\nfrom time import time\nimport math\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_squared_error,mean_absolute_error\nimport tensorflow as tf\nfrom keras import optimizers",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Using TensorFlow backend.\n",
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "91fc82a9e7fdb00970a193f17d72e189bd5b71ae"
      },
      "cell_type": "code",
      "source": "print(os.listdir(\"../input/testcs/train.csv\"))",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": "['train.csv']\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "29e2950b03297762e4548ac71b866807fc77b5ce"
      },
      "cell_type": "code",
      "source": "def ReadData():\n    train1 = pd.read_csv(\"../input/testcs/train.csv\",encoding ='latin1')\n    test1 = pd.read_csv(\"../input/trainc/tratestin.csv\",encoding ='latin1')\n    desc1 = pd.read_csv(\"../input/product_descriptions.csv\",encoding ='latin1')\n    sample1 = pd.read_csv(\"../input/sample_submission.csv\",encoding ='latin1')\n    attributes1 = pd.read_csv(\"../input/attributes.csv\",encoding ='latin1')\n    return train1,test1,desc1,sample1,attributes1\ndef ConcatDescAndTitle(df):\n    train1 = df.merge(desc,on='product_uid',how='left')\n    #train1['TitleAndDesc'] = train1[['product_title', 'product_description']].apply(lambda x: ''.join(x), axis=1)\n    train1 = train1.drop(columns=['product_description','id'])\n    #train1['product_title'] = train1['product_title'].str.replace('[^a-zA-Z0-9\\s]','$')\n    #train1['search_term'] = train1['search_term'].str.replace('[^a-zA-Z0-9\\s]','$')\n    train1['product_title'] = train1['product_title'].str.replace('\\\\xa0', '')\n    train1['search_term'] = train1['search_term'].str.replace('\\\\xa0', '')\n    return train1\ndef LeftRightAndY(df):\n    left = df[\"product_title\"]\n    right = df[\"search_term\"]\n    y = df[\"relevance\"]\n    return left,right,y\ndef getBrandAndMatirial():\n    for i in range(train.shape[0]):\n        if (i%1000==0):\n            print(i)\n        row = train.loc[i]\n        #foo = df.ix[(df['column1']==value) | (df['columns2'] == 'b') | (df['column3'] == 'c')]\n        row2 = attributes[attributes[\"product_uid\"]==row[\"product_uid\"]]\n        brand = row2[row2[\"name\"]==str(\"MFG Brand Name\")][\"value\"]\n        Material = row2[row2[\"name\"]==str(\"Material\")][\"value\"]\n        if ((brand.values.any())):\n            if ((Material.values.any())):\n                train.loc[i,\"product_title\"] += \" \" + str(brand.values[0]) + \" \" + str(Material.values[0])\n    return train",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "trusted": true
      },
      "cell_type": "code",
      "source": "train,test,desc,sample,attributes = ReadData()\ntrain = ConcatDescAndTitle(train)\ntest = ConcatDescAndTitle(test)\ntrain = getBrandAndMatirial()\n#input_left,input_right,y = LeftRightAndY(train)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "10ae7c0076d21dd8f57180083cf5b38776817a64"
      },
      "cell_type": "code",
      "source": "train.to_csv('train.csv',index=False)\ntest.to_csv('tratestin.csv',index=False)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "7f4473c27b69c4612ae3b88aa963d48a8d4504ec"
      },
      "cell_type": "raw",
      "source": ""
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "0a60bbb758c361613ebbd8557713299cb191bfa1"
      },
      "cell_type": "code",
      "source": "def CreateDic():\n    CharToIndex2 = {}\n    counter=0\n    for key in model.wv.vocab.keys():\n        CharToIndex2[key] = counter\n        counter += 1\n    return CharToIndex2\ndef CreateOneHot(index):\n    arr = np.zeros(lenthofchar)\n    arr[index] = 1\n    return arr",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "24074dde91a9b613247e6437eaba33116dfdbf11"
      },
      "cell_type": "code",
      "source": "y_train=train[\"relevance\"]\nuntil = train.shape[0]*0.85\nX_train = train.loc[:until,:]\nX_test = train.loc[until:,:]\nY_train = y_train.loc[:until]\nY_test = y_train.loc[until:]\navg = 0\nchars = \"abcdefghijklmnopqrstuvwxyz ABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789\"\nfor i in range(X_train.shape[0]):\n    lis =(list(X_train.loc[i][\"product_title\"]))\n    avg += len(lis)\navg_len = avg/X_train.shape[0]\navg_len =int(math.floor(avg_len))\navg_len=60\nlenthofchar = len(chars)\nx_train_left = np.empty([X_train.shape[0],avg_len,lenthofchar])\nfor i in range(X_train.shape[0]):\n    lis =(list(X_train.loc[i][\"product_title\"]))\n    for j in range(avg_len):\n        if (j<len(lis)):\n            x_train_left[i][j] = CreateOneHot(chars.find(lis[j]))\n        else:\n            x_train_left[i][j] = CreateOneHot(chars.find(\"$\"))\nx_train_right = np.empty([X_train.shape[0],avg_len,lenthofchar])\nfor i in range(X_train.shape[0]):\n    lis2 =(list(X_train.loc[i][\"search_term\"]))\n    for j in range(avg_len):\n        if (j<len(lis2)):\n            x_train_right[i][j] = CreateOneHot(chars.find(lis2[j]))\n        else:\n            x_train_right[i][j] = CreateOneHot(chars.find(\"$\"))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "b2f1ae5f58d9783eafacf735ed9dc5f2b5edf37a"
      },
      "cell_type": "code",
      "source": "def cossim(left, right):\n    ans = (K.sum(left*right))/(K.sqrt(K.sum(K.pow(left,2)))*K.sqrt(K.sum(K.pow(right,2))))\n    ans = tf.nn.relu(ans)\n    return ans*2 +1",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "9a38a275b6f0b4b4716537242bb49cb467cc5aed"
      },
      "cell_type": "code",
      "source": "y_train=train[\"relevance\"]\nY_train = y_train.loc[:until]\nY_test = y_train.loc[until:]\nY_train = np_utils.to_categorical(Y_train, 13)\nY_test = np_utils.to_categorical(Y_test, 13)\nprint(Y_train[8])\nprint(train.head(50))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "c3a3692e08a69fbcbdfc513ed8f29957eaa5a0e6"
      },
      "cell_type": "code",
      "source": "margin = 0.3",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "db6ea059d1b99ac0df1834ab3f06707c546c2e7a"
      },
      "cell_type": "code",
      "source": "def custum_mean_squared_error(y_true, y_pred):\n    return K.mean(K.square(((y_pred - y_true)))+(y_pred - y_true)*margin, axis=-1)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "7c77f8c54461f8a117aa303bd34e72b32c3e34ab"
      },
      "cell_type": "markdown",
      "source": "**THE LSTM NetWork**"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "c621041127cb095f45e74bcd4bf08a58e629a4ff",
        "scrolled": false
      },
      "cell_type": "code",
      "source": "n_hidden = 150\nbatch_size = 1500\nn_epoch = 1\nleft_input = Input(shape=(x_train_left.shape[1], x_train_left.shape[2]))\nright_input = Input(shape=(x_train_left.shape[1], x_train_left.shape[2]))\nshared_lstm = LSTM(n_hidden)\n\nleft_out = shared_lstm(left_input)\nright_out = shared_lstm(right_input)\nleft_out_norm = BatchNormalization()(left_out)\nright_out_norm = BatchNormalization()(right_out)\nmerged_vector = concatenate([left_out_norm, right_out_norm], axis=-1)\n#malstm_distance = Lambda(function=lambda x: cossim(x[0], x[1]),output_shape=lambda x: (1, 1))([left_out, right_out])\npredictions2 = Dense(20,activation=\"sigmoid\")(merged_vector)\npredictions3 = Dense(13,activation=\"softmax\")(predictions2)\n# Pack it all up into a model\nmalstm = Model([left_input, right_input], [predictions3])\n\n#optimizer = Adadelta(clipnorm=1.25)\n#malstm.compile(loss='mse', optimizer=\"adam\", metrics=['accuracy'])\n#sgd = optimizers.SGD(lr=0.0001, decay=1e-6, momentum=0.9, nesterov=True)\n\nmalstm.compile(loss='mse', optimizer=\"adam\", metrics=['accuracy'])\nmalstm.summary()\n# Start training\ntraining_start_time = time()\nmalstm_trained = malstm.fit([x_train_left, x_train_right],Y_train, batch_size=batch_size, nb_epoch=n_epoch,validation_split=0.05)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "d64f94ec85d925a31be5361f4ec6025521f1d7cb"
      },
      "cell_type": "markdown",
      "source": "**Good One:**"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "12abdb763a2876e1ffe3c495cc42748d8ecab1ef"
      },
      "cell_type": "code",
      "source": "val = int(math.floor(until))+X_test.shape[0]\nx_test_left = np.empty([X_test.shape[0],60,lenthofchar])\nfor i in range(int(math.floor(until))+1,val):\n    lis =(list(X_test.loc[i][\"product_title\"]))\n    for j in range(60):\n        if (j<len(lis)):\n            if ([lis[j]]!='\\xa0'):\n                x_test_left[i-int(math.floor(until))-1][j] = CreateOneHot(chars.find(lis[j]))\n            else:\n                x_test_left[i-int(math.floor(until)-1)][j] =  CreateOneHot(chars.find(\"$\")) \nx_test_right = np.empty([X_test.shape[0],60,lenthofchar])\nfor i in range(int(math.floor(until))+1,val):\n    lis2 =(list(X_test.loc[i][\"search_term\"]))\n    for j in range(60):\n        if (j<len(lis2)):\n            if ([lis2[j]]!='\\xa0'):\n                x_test_right[i-int(math.floor(until))-1][j] = CreateOneHot(chars.find(lis2[j]))\n            else:\n                x_test_right[i-int(math.floor(until))-1][j] = CreateOneHot(chars.find(\"$\"))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "1ce394df10895895e6d471a489d45dc70701a1d8"
      },
      "cell_type": "code",
      "source": "preds = malstm.predict([x_test_left, x_test_right], batch_size=batch_size)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "2832981e59b3fc9875f720893e72559238b40092"
      },
      "cell_type": "code",
      "source": "rmse = np.sqrt(mean_squared_error(preds, Y_test))\nMAE = mean_absolute_error(preds, Y_test)\nprint('Test RMSE: %.3f' % rmse)\nprint('Test MAE: %.3f' % MAE)\nplt.plot(malstm_trained.history['loss'])\nplt.plot(malstm_trained.history['val_loss'])\nplt.title('model loss')\nplt.ylabel('acc')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper right')\nplt.show()\naa=[x for x in range(100)]\nplt.plot(aa, Y_test[:100], marker='.', label=\"actual\")\nplt.plot(aa, preds[:100], 'r', label=\"prediction\")\nplt.ylabel('Relevance', size=15)\nplt.xlabel('Time step', size=15)\nplt.legend(fontsize=15)\nplt.show()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "cbcd79c5bf96ed4bda214be462d2dd7afb8e607b"
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.6",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}